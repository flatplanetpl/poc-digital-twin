# FR-P0-1: Grounded Answers

**Status:** âœ… Zaimplementowane (v1.0)

Grounded Answers to fundament zaufania do systemu â€” odpowiedzi **wyÅ‚Ä…cznie** na podstawie Twoich dokumentÃ³w z **obowiÄ…zkowymi cytatami**.

---

## Problem

Tradycyjne modele jÄ™zykowe (LLM) majÄ… tendencjÄ™ do "halucynacji" â€” generowania odpowiedzi, ktÃ³re brzmiÄ… przekonujÄ…co, ale sÄ… caÅ‚kowicie zmyÅ›lone. To szczegÃ³lnie niebezpieczne gdy:

- Pytasz o **fakty z wÅ‚asnych dokumentÃ³w** (daty, kwoty, ustalenia)
- Podejmujesz **decyzje biznesowe** na podstawie odpowiedzi
- Sprawdzasz **historiÄ™ komunikacji** (kto co powiedziaÅ‚)

**PrzykÅ‚ad halucynacji:**

```
Pytanie: Kiedy umÃ³wiÅ‚em siÄ™ z AnnÄ…?

âŒ Typowe LLM: "UmÃ³wiÅ‚eÅ› siÄ™ z AnnÄ… na piÄ…tek o 14:00."
   (skÄ…d to wie? wymyÅ›liÅ‚o!)

âœ… Digital Twin: "Nie mogÅ‚em znaleÅºÄ‡ informacji o spotkaniu z AnnÄ…
   w Twoich dokumentach."
   (uczciwe â€” jeÅ›li nie ma danych, mÃ³wi Å¼e nie wie)
```

---

## RozwiÄ…zanie

Digital Twin uÅ¼ywa specjalnego **Grounded System Prompt**, ktÃ³ry wymusza:

1. **TYLKO kontekst** â€” LLM moÅ¼e uÅ¼ywaÄ‡ wyÅ‚Ä…cznie dostarczonych fragmentÃ³w
2. **ObowiÄ…zkowe cytaty** â€” kaÅ¼dy fakt musi mieÄ‡ ÅºrÃ³dÅ‚o
3. **Przyznanie siÄ™ do niewiedzy** â€” jeÅ›li nie ma danych, mÃ³wi wprost

### Grounded System Prompt

```
JesteÅ› osobistym asystentem danych. Odpowiadaj TYLKO na podstawie kontekstu.

KRYTYCZNE ZASADY:
1. UÅ¼ywaj WYÅÄ„CZNIE informacji jawnie zawartych w kontekÅ›cie poniÅ¼ej
2. JeÅ›li informacji nie ma: "Nie mogÅ‚em znaleÅºÄ‡ tej informacji w Twoich danych."
3. NIGDY nie uÅ¼ywaj wiedzy z treningu modelu
4. ZAWSZE cytuj ÅºrÃ³dÅ‚o: [Å¹rÃ³dÅ‚o: {typ}, {data}, "{fragment}"]

Kontekst:
{context_str}

Pytanie: {query_str}
```

---

## Struktura cytatu

KaÅ¼dy cytat zawiera peÅ‚ne metadane ÅºrÃ³dÅ‚a:

```python
@dataclass
class Citation:
    document_id: str      # UUID dokumentu (do Å›ledzenia/usuwania)
    source_type: str      # email, note, whatsapp, messenger
    filename: str         # Nazwa pliku ÅºrÃ³dÅ‚owego
    date: str             # Data dokumentu
    fragment: str         # Cytowany fragment (do 100 znakÃ³w)
    score: float          # Wynik podobieÅ„stwa (0.0 - 1.0)
```

### PrzykÅ‚ad cytatu w odpowiedzi

```
Zgodnie z Twoimi dokumentami, spotkanie zostaÅ‚o przeÅ‚oÅ¼one na poniedziaÅ‚ek.

[Å¹rÃ³dÅ‚o: email, 2024-12-10, "Musimy przeÅ‚oÅ¼yÄ‡ spotkanie na poniedziaÅ‚ek..."]
[Å¹rÃ³dÅ‚o: whatsapp, 2024-12-10, "Ok, to w poniedziaÅ‚ek o 10"]
```

---

## UÅ¼ycie w kodzie

### Podstawowe zapytanie z cytatami

```python
from src.rag import RAGEngine

engine = RAGEngine()

result = engine.query("Kiedy mam spotkanie z klientem?")

# OdpowiedÅº
print(result["answer"])

# Cytaty
for citation in result["citations"]:
    print(f"ğŸ“ [{citation['source_type']}] {citation['filename']}")
    print(f"   Data: {citation['date']}")
    print(f"   Fragment: {citation['fragment']}")
    print(f"   Score: {citation['score']:.2f}")
```

### Sprawdzanie uziemienia

```python
result = engine.query("Co obiecaÅ‚em Markowi?")

if result["is_grounded"]:
    print("âœ… OdpowiedÅº oparta na dokumentach")
else:
    print("âš ï¸ UWAGA: OdpowiedÅº moÅ¼e zawieraÄ‡ treÅ›ci spoza kontekstu")

if result["no_context_found"]:
    print("âŒ Nie znaleziono pasujÄ…cych dokumentÃ³w")
```

### GroundedResponse â€” peÅ‚na struktura

```python
from src.rag.citations import GroundedResponse

# GroundedResponse zawiera:
@dataclass
class GroundedResponse:
    answer: str                    # TreÅ›Ä‡ odpowiedzi
    citations: list[Citation]      # Lista cytatÃ³w
    is_grounded: bool              # Czy odpowiedÅº jest uziemiona
    no_context_found: bool         # Czy nie znaleziono kontekstu
    conversation_id: int | None    # ID konwersacji
    query_time_ms: float           # Czas zapytania

    @property
    def sources(self) -> list[dict]:
        """Legacy format dla kompatybilnoÅ›ci."""
        return [c.to_dict() for c in self.citations]
```

---

## Walidacja uziemienia

System automatycznie sprawdza czy odpowiedÅº jest prawidÅ‚owo uziemiona:

```python
from src.rag.citations import validate_grounding

# Funkcja sprawdza:
# 1. Czy odpowiedÅº zawiera cytaty
# 2. Czy cytaty odpowiadajÄ… faktycznie pobranym dokumentom
# 3. Czy odpowiedÅº nie zawiera "halucynacji"

is_grounded = validate_grounding(answer_text, citations)
```

### Heurystyki walidacji

| Warunek | Wynik |
|---------|-------|
| OdpowiedÅº zawiera `[Å¹rÃ³dÅ‚o: ...]` | +1 do grounding |
| Cytaty pasujÄ… do pobranych dokumentÃ³w | +1 do grounding |
| OdpowiedÅº mÃ³wi "nie znaleziono" przy braku kontekstu | âœ… Grounded |
| OdpowiedÅº podaje fakty bez cytatÃ³w | âŒ Not grounded |

---

## Ekstrakcja cytatÃ³w

System automatycznie wyciÄ…ga cytaty z odpowiedzi LLM:

```python
from src.rag.citations import extract_citations

# Z listy NodeWithScore (LlamaIndex)
citations = extract_citations(response.source_nodes)

for c in citations:
    print(f"{c.source_type}: {c.fragment[:50]}... (score: {c.score:.2f})")
```

---

## Konfiguracja

### Prompt systemowy

MoÅ¼esz dostosowaÄ‡ prompt w `src/rag/query_engine.py`:

```python
class RAGEngine:
    SYSTEM_PROMPT = GROUNDED_SYSTEM_PROMPT  # Z citations.py
```

### Lub uÅ¼yÄ‡ wÅ‚asnego:

```python
from src.rag.citations import GROUNDED_SYSTEM_PROMPT

custom_prompt = GROUNDED_SYSTEM_PROMPT + """

DODATKOWE ZASADY:
- Odpowiadaj po polsku
- UÅ¼ywaj punktÃ³w dla listy faktÃ³w
"""
```

---

## PrzykÅ‚ady odpowiedzi

### OdpowiedÅº z cytatami âœ…

```
Pytanie: Jaki jest budÅ¼et projektu Alpha?

OdpowiedÅº: BudÅ¼et projektu Alpha wynosi 150,000 PLN, zatwierdzony
przez zarzÄ…d 15 listopada 2024.

[Å¹rÃ³dÅ‚o: email, 2024-11-15, "BudÅ¼et projektu Alpha w wysokoÅ›ci 150k PLN
zostaÅ‚ zatwierdzony..."]
[Å¹rÃ³dÅ‚o: note, 2024-11-16, "Notatka: Alpha - budÅ¼et 150,000 zaakceptowany"]
```

### Przyznanie siÄ™ do niewiedzy âœ…

```
Pytanie: Ile zarabia mÃ³j kolega Tomek?

OdpowiedÅº: Nie mogÅ‚em znaleÅºÄ‡ informacji o zarobkach Tomka
w Twoich zindeksowanych dokumentach.

Ta informacja moÅ¼e nie byÄ‡ zapisana w Twoich notatkach,
e-mailach lub wiadomoÅ›ciach.
```

### OdpowiedÅº warunkowa âœ…

```
Pytanie: Kiedy jest deadline projektu?

OdpowiedÅº: W Twoich dokumentach znalazÅ‚em rÃ³Å¼ne daty deadline'u:

1. **WstÄ™pny deadline**: 15 stycznia 2025
   [Å¹rÃ³dÅ‚o: email, 2024-10-01, "Planujemy zakoÅ„czenie na 15.01..."]

2. **PrzeÅ‚oÅ¼ony deadline**: 31 marca 2025
   [Å¹rÃ³dÅ‚o: note, 2024-11-20, "Nowy deadline: koniec Q1 2025"]

Najnowsza informacja wskazuje na 31 marca 2025.
```

---

## Troubleshooting

### Problem: Brak cytatÃ³w w odpowiedzi

**Przyczyny:**
1. LLM ignoruje instrukcje z promptu
2. Brak pasujÄ…cych dokumentÃ³w

**RozwiÄ…zania:**
```python
# SprawdÅº czy sÄ… dokumenty
result = engine.query("test", include_explanation=True)
print(f"DokumentÃ³w pobranych: {len(result['explanation']['documents_retrieved'])}")

# JeÅ›li 0 â€” problem z wyszukiwaniem
# JeÅ›li >0 ale brak cytatÃ³w â€” problem z LLM
```

### Problem: Odpowiedzi "halucynujÄ…" mimo promptu

**RozwiÄ…zania:**
1. UÅ¼yj silniejszego modelu (GPT-4, Claude 3)
2. Zmniejsz temperaturÄ™ LLM (jeÅ›li konfigurowalna)
3. Dodaj wiÄ™cej przykÅ‚adÃ³w w prompcie

### Problem: Cytaty nie pasujÄ… do odpowiedzi

```python
# WÅ‚Ä…cz tryb debug
import logging
logging.getLogger("src.rag").setLevel(logging.DEBUG)

result = engine.query("...", include_explanation=True)
# SprawdÅº ktÃ³re dokumenty zostaÅ‚y faktycznie uÅ¼yte
```

---

## PowiÄ…zane

- **[FR-P0-4: Explainability](FR-P0-4-Explainability)** â€” zobacz dokÅ‚adnie ktÃ³re fragmenty weszÅ‚y do kontekstu
- **[Pipelines](Pipelines)** â€” jak dziaÅ‚a pipeline RAG
- **[API Reference](API-Reference)** â€” peÅ‚na dokumentacja Citation i GroundedResponse

---

<p align="center">
  <a href="Podstawy-uÅ¼ytkowania">â† Podstawy uÅ¼ytkowania</a> |
  <a href="Home">Strona gÅ‚Ã³wna</a> |
  <a href="FR-P0-2-Offline-Mode">FR-P0-2: Offline Mode â†’</a>
</p>

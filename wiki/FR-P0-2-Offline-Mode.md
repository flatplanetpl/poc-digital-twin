# FR-P0-2: Offline Mode

**Status:** ‚úÖ Zaimplementowane (v1.0)

Tryb offline gwarantuje, ≈ºe **≈ºadne Twoje dane nie opuszczƒÖ komputera** ‚Äî nawet przypadkowo.

---

## Problem

Przy pracy z wra≈ºliwymi danymi (dokumenty prawne, medyczne, finansowe, osobiste) istnieje ryzyko:

1. **Przypadkowe u≈ºycie API chmurowego** ‚Äî dane wys≈Çane do OpenAI/Anthropic
2. **Brak kontroli** ‚Äî nie wiesz co zosta≈Ço wys≈Çane
3. **Compliance** ‚Äî naruszenie RODO, tajemnicy zawodowej, NDA

**Przyk≈Çad ryzyka:**

```python
# Przypadkowa zmiana providera...
engine.set_llm_provider("openai")

# ...a potem zapytanie o wra≈ºliwe dane
engine.query("Jakie sƒÖ warunki umowy z klientem X?")
# üò± Tre≈õƒá umowy zosta≈Ça w≈Ça≈õnie wys≈Çana do OpenAI!
```

---

## RozwiƒÖzanie

Digital Twin oferuje **config-level protection** ‚Äî tryb offline wymuszany przez konfiguracjƒô:

```bash
# W .env:
OFFLINE_MODE=true
```

Gdy tryb offline jest aktywny:
- ‚úÖ Tylko `gpt4all` (lokalny) jest dostƒôpny
- ‚ùå OpenAI, Anthropic ‚Äî zablokowane
- ‚ùå Pr√≥ba u≈ºycia ‚Üí `OfflineModeError`

---

## Konfiguracja

### Pe≈Çny tryb offline

```bash
# .env
OFFLINE_MODE=true
```

Efekt:
- Tylko GPT4All dostƒôpny
- Wszystkie dane przetwarzane lokalnie
- Brak po≈ÇƒÖcze≈Ñ wychodzƒÖcych do API LLM

### Tryb "tylko lokalne"

```bash
# .env
OFFLINE_MODE=false
ALLOW_CLOUD_LLM=false
```

Efekt:
- Tylko GPT4All dostƒôpny
- Ale system nie jest w "trybie offline" (inne funkcje mogƒÖ dzia≈Çaƒá)

### Pe≈Çny dostƒôp (domy≈õlny)

```bash
# .env
OFFLINE_MODE=false
ALLOW_CLOUD_LLM=true
```

Efekt:
- Wszystkie providery dostƒôpne
- U≈ºytkownik sam wybiera

---

## Macierz konfiguracji

| OFFLINE_MODE | ALLOW_CLOUD_LLM | gpt4all | openai | anthropic | Dane wysy≈Çane? |
|:------------:|:---------------:|:-------:|:------:|:---------:|:--------------:|
| `false` | `true` | ‚úÖ | ‚úÖ | ‚úÖ | Mo≈ºliwe* |
| `false` | `false` | ‚úÖ | ‚ùå | ‚ùå | Nie |
| `true` | `true`** | ‚úÖ | ‚ùå | ‚ùå | Nie |
| `true` | `false` | ‚úÖ | ‚ùå | ‚ùå | Nie |

\* Je≈õli u≈ºytkownik wybierze cloud LLM
\*\* OFFLINE_MODE nadpisuje ALLOW_CLOUD_LLM

---

## U≈ºycie w kodzie

### Sprawdzanie trybu

```python
from src.config import settings

# Czy system jest w trybie offline?
print(f"Offline mode: {settings.offline_mode}")
print(f"Allow cloud: {settings.allow_cloud_llm}")
print(f"Is offline: {settings.is_offline}")

# Dostƒôpni providerzy
print(f"Dostƒôpne LLM: {settings.available_llm_providers}")
```

### Obs≈Çuga OfflineModeError

```python
from src.llm import create_llm, OfflineModeError

try:
    llm = create_llm("openai")
except OfflineModeError as e:
    print(f"‚ùå Zablokowane: {e}")
    # Fallback do lokalnego
    llm = create_llm("gpt4all")
```

### Lista dostƒôpnych provider√≥w

```python
from src.llm import get_available_providers

providers = get_available_providers()
print(f"Mo≈ºesz u≈ºyƒá: {providers}")

# W trybie offline: ['gpt4all']
# W trybie online: ['gpt4all', 'openai', 'anthropic']
```

### Dynamiczna zmiana trybu

```python
import os

# W≈ÇƒÖcz tryb offline programowo
os.environ["OFFLINE_MODE"] = "true"

# Reload settings
from src.config import Settings
settings = Settings()

print(f"Teraz offline: {settings.is_offline}")
```

---

## Wska≈∫niki w UI

Gdy tryb offline jest aktywny, interfejs Streamlit wy≈õwietla ostrze≈ºenie:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚ö†Ô∏è TRYB OFFLINE                         ‚îÇ
‚îÇ Chmurowe LLM sƒÖ wy≈ÇƒÖczone.              ‚îÇ
‚îÇ Wszystkie dane przetwarzane lokalnie.   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Dodatkowo w sidebarze:
- Przyciski OpenAI/Anthropic sƒÖ **wyszarzone**
- Tooltip wyja≈õnia dlaczego

---

## Scenariusze u≈ºycia

### Praca z dokumentami prawnymi

```bash
# Przed pracƒÖ:
export OFFLINE_MODE=true
streamlit run src/ui/app.py

# Teraz bezpieczne przeglƒÖdanie um√≥w, NDA, itp.
```

### Analiza danych medycznych

```bash
# .env dla tej sesji
OFFLINE_MODE=true
LLM_PROVIDER=gpt4all
GPT4ALL_MODEL=mistral-7b-instruct-v0.1.Q4_0.gguf
```

### Demo bez internetu

```bash
# Na prezentacji bez WiFi
OFFLINE_MODE=true
python scripts/ingest.py --source ./demo-data/
streamlit run src/ui/app.py
# Wszystko dzia≈Ça lokalnie!
```

### Prze≈ÇƒÖczanie trybu per-sesja

```bash
# Sesja 1: Praca z wra≈ºliwymi danymi
OFFLINE_MODE=true streamlit run src/ui/app.py

# Sesja 2: Normalna praca (nowe okno terminala)
OFFLINE_MODE=false LLM_PROVIDER=openai streamlit run src/ui/app.py
```

---

## Implementacja techniczna

### Sprawdzanie w factory

```python
# src/llm/factory.py

_CLOUD_PROVIDERS = {"openai", "anthropic"}

def create_llm(provider: str | None = None) -> BaseLLM:
    provider = provider or settings.llm_provider

    # Sprawd≈∫ czy cloud provider jest dozwolony
    if provider in _CLOUD_PROVIDERS:
        if settings.offline_mode:
            raise OfflineModeError(
                f"Cannot use cloud LLM '{provider}' in offline mode. "
                f"Use 'gpt4all' or disable OFFLINE_MODE."
            )
        if not settings.allow_cloud_llm:
            raise OfflineModeError(
                f"Cloud LLM '{provider}' is disabled. "
                f"Set ALLOW_CLOUD_LLM=true or use 'gpt4all'."
            )

    # ... tworzenie providera
```

### Property w Settings

```python
# src/config.py

class Settings(BaseSettings):
    offline_mode: bool = False
    allow_cloud_llm: bool = True

    @property
    def available_llm_providers(self) -> list[str]:
        """Dostƒôpni providerzy w obecnej konfiguracji."""
        if self.offline_mode or not self.allow_cloud_llm:
            return ["gpt4all"]
        return ["gpt4all", "openai", "anthropic"]

    @property
    def is_offline(self) -> bool:
        """Czy system jest efektywnie offline."""
        return self.offline_mode or not self.allow_cloud_llm
```

---

## Bezpiecze≈Ñstwo

### Co jest chronione?

| Komponent | W trybie online | W trybie offline |
|-----------|-----------------|------------------|
| Embeddingi | Lokalnie (HuggingFace) | Lokalnie |
| Wyszukiwanie (Qdrant) | Lokalnie | Lokalnie |
| Generowanie (LLM) | Cloud lub lokalnie | Tylko lokalnie |
| Historia czat√≥w | Lokalnie (SQLite) | Lokalnie |
| Audyt | Lokalnie (SQLite) | Lokalnie |

### Co NIE jest chronione przez offline mode?

- **Pobieranie modeli** ‚Äî pierwszy raz model GPT4All jest pobierany z internetu
- **Aktualizacje** ‚Äî `pip install` wymaga internetu
- **Inne po≈ÇƒÖczenia** ‚Äî system nie blokuje ca≈Çego internetu, tylko API LLM

### Pe≈Çna izolacja sieciowa

Dla maksymalnej ochrony mo≈ºesz:

```bash
# 1. Pobierz model wcze≈õniej
mkdir -p ~/.cache/gpt4all
wget -O ~/.cache/gpt4all/mistral-7b-instruct-v0.1.Q4_0.gguf \
  https://gpt4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf

# 2. Od≈ÇƒÖcz od sieci
nmcli networking off  # Linux
# lub fizycznie od≈ÇƒÖcz kabel/WiFi

# 3. Uruchom w trybie offline
OFFLINE_MODE=true streamlit run src/ui/app.py
```

---

## Troubleshooting

### Problem: "OfflineModeError" przy starcie

```bash
# Sprawd≈∫ konfiguracjƒô
cat .env | grep -E "OFFLINE|ALLOW_CLOUD|LLM_PROVIDER"

# Je≈õli LLM_PROVIDER=openai i OFFLINE_MODE=true ‚Üí b≈ÇƒÖd
# RozwiƒÖzanie:
LLM_PROVIDER=gpt4all
```

### Problem: GPT4All wolny w trybie offline

To normalne ‚Äî lokalny model jest wolniejszy ni≈º API chmurowe.

**Optymalizacje:**
1. U≈ºyj mniejszego modelu: `GPT4ALL_MODEL=orca-mini-3b-gguf2-q4_0.gguf`
2. Zmniejsz TOP_K: mniej kontekstu = szybsza odpowied≈∫
3. Rozwa≈º GPU (kompilacja z CUDA)

### Problem: Chcƒô czasem u≈ºywaƒá OpenAI

```bash
# Stw√≥rz dwa pliki konfiguracji

# .env.offline (dla wra≈ºliwych danych)
OFFLINE_MODE=true
LLM_PROVIDER=gpt4all

# .env.online (normalna praca)
OFFLINE_MODE=false
LLM_PROVIDER=openai

# Prze≈ÇƒÖczaj przez:
cp .env.offline .env
# lub
cp .env.online .env
```

---

## PowiƒÖzane

- **[Konfiguracja](Konfiguracja)** ‚Äî wszystkie opcje .env
- **[FR-P0-5: Forget/RTBF](FR-P0-5-Forget-RTBF)** ‚Äî usuwanie danych (dla pe≈Çnej kontroli)
- **[Instalacja](Instalacja)** ‚Äî jak zainstalowaƒá GPT4All

---

<p align="center">
  <a href="FR-P0-1-Grounded-Answers">‚Üê FR-P0-1: Grounded Answers</a> |
  <a href="Home">Strona g≈Ç√≥wna</a> |
  <a href="FR-P0-3-Priority-Rules">FR-P0-3: Priority Rules ‚Üí</a>
</p>
